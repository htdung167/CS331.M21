{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CaiDatLinearVaLogistic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Thông tin sinh viên:**"
      ],
      "metadata": {
        "id": "BDbH-ypUcuL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* MSSV: 19521388\n",
        "* Họ và tên: Hoàng Tiến Dũng\n",
        "* Lớp môn học: CS331.M11\n",
        "* Bài tập: Cài đặt Linear Regression và Logistic Regression bằng Numpy"
      ],
      "metadata": {
        "id": "QRc8rQSScwRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bài làm:**"
      ],
      "metadata": {
        "id": "QhW-BevNc_Ke"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ANlWCRRWcoB7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**I. Linear Regression**"
      ],
      "metadata": {
        "id": "0RSQi-8kdDxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def cost_function(self, X, y, theta):\n",
        "    m = len(y)\n",
        "    y_pred = X@theta\n",
        "    return (1/(2*m)) * np.sum((y_pred-y)**2)\n",
        "  \n",
        "  def gradient_descent(self, X, y, theta, iters, alpha):\n",
        "    m = len(y)\n",
        "    costs = []\n",
        "    for i in range(iters):\n",
        "      y_pred = X@theta\n",
        "      theta -= (alpha/m * (X.T@(y_pred-y))) #Vector hóa\n",
        "      costs.append(self.cost_function(X, y,theta))\n",
        "    return theta, costs\n",
        "\n",
        "  def fit(self, X, y, iters=15, learning_rate=0.01):\n",
        "    m = len(y)\n",
        "    n = len(X[0])\n",
        "    self.X_train = np.append(np.ones((m,1)), X.copy(), axis=1) #X: mxn\n",
        "    self.y_train = y #y : mx1\n",
        "    self.theta = np.zeros((n + 1, 1)) # theta = nx1\n",
        "    self.theta, self.costs = self.gradient_descent(self.X_train, self.y_train, self.theta, iters=iters, alpha=learning_rate)\n",
        "    return self.theta, self.costs\n",
        "  \n",
        "  def predict(self, X_pred):\n",
        "    X_pred_t = np.append(np.ones((len(X_pred), 1)), X_pred, axis=1)\n",
        "    return X_pred_t@self.theta"
      ],
      "metadata": {
        "id": "0ZVGRIsjdA9E"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**II. Logistic Regression**"
      ],
      "metadata": {
        "id": "hzIyuh-bdhxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "    return 1.0/(1.0 + np.exp(-z))\n",
        "\n",
        "  def cost_function_1(self, X, y, theta): #cross entropy\n",
        "    m = len(y)\n",
        "    y_pred = self.sigmoid(X@theta)\n",
        "    cost = -1.0* np.mean(y*np.log(y_pred) + (1-y)*np.log(1-y_pred))\n",
        "    return cost\n",
        "\n",
        "  def gradient_descent_1(self, X, y, theta, iters , alpha ):\n",
        "    m = len(y)\n",
        "    costs = []\n",
        "    for i in range(iters):\n",
        "      h = self.sigmoid(X@theta)\n",
        "      gradient = X.T@(h-y) \n",
        "      theta -= alpha / m * gradient \n",
        "      costs.append(self.cost_function_1(X, y, theta))\n",
        "    return theta, costs\n",
        "\n",
        "  def cost_function_2(self, X, y, theta): #mean squared error\n",
        "    m = len(y)\n",
        "    y_pred = self.sigmoid(X@theta)\n",
        "    return (1/(2*m)) * np.sum((y_pred-y)**2)\n",
        "\n",
        "  def gradient_descent_2(self, X, y, theta, iters,alpha):\n",
        "    m = len(y)\n",
        "    costs = []\n",
        "    for i in range(iters):\n",
        "      y_pred = self.sigmoid(X@theta)\n",
        "      theta -= (alpha/m * (X.T@(y_pred-y)))\n",
        "      costs.append(self.cost_function_2(X, y,theta))\n",
        "    return theta, costs\n",
        "\n",
        "  def fit(self, X, y, iters=15, learning_rate=0.01, loss=\"crossentropy\"):\n",
        "    m = len(y)\n",
        "    n = len(X[0])\n",
        "    self.X_train = np.append(np.ones((m,1)), X, axis=1) #X: mxn\n",
        "    self.y_train = y #y : mx1\n",
        "    self.theta = np.zeros((n + 1, 1)) # theta = nx1\n",
        "    if loss == \"crossentropy\":\n",
        "      self.theta, self.costs = self.gradient_descent_1(self.X_train, self.y_train, self.theta, iters=iters, alpha = learning_rate)\n",
        "    elif loss == 'mse':\n",
        "      self.theta, self.costs = self.gradient_descent_2(self.X_train, self.y_train, self.theta, iters=iters, alpha = learning_rate)\n",
        "    return self.theta, self.costs\n",
        "\n",
        "  def predict(self, X_pred):\n",
        "    X_pred_t = np.append(np.ones((len(X_pred), 1)), X_pred, axis=1)\n",
        "    pred = self.sigmoid(X_pred_t@self.theta)\n",
        "    return np.where(pred < 0.5, 0, 1)"
      ],
      "metadata": {
        "id": "W2gXwqFZdlDv"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**III. Thực nghiệm**"
      ],
      "metadata": {
        "id": "b2lO5AvuyGvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Linear Regression**"
      ],
      "metadata": {
        "id": "CBhU61ODyvTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZTMZv6RyE9y",
        "outputId": "295f43b6-d641-4202-9678-4412576e166d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Private_ThiGiacMayTinhNangCao/Real estate.csv', index_col=0)\n",
        "df_new = df.drop(df.columns[[0,2]], axis=1)\n",
        "X = df_new.iloc[:,0:4]\n",
        "y = df_new.iloc[:,-1]"
      ],
      "metadata": {
        "id": "htwunz08yd4V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X.to_numpy()\n",
        "y=y.to_numpy()\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrpskmRRylJQ",
        "outputId": "2cf2e41a-8e73-4df2-b0be-f78514130fba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 32.       10.       24.98298 121.54024]\n",
            " [ 19.5       9.       24.98034 121.53951]\n",
            " [ 13.3       5.       24.98746 121.54391]\n",
            " ...\n",
            " [ 18.8       7.       24.97923 121.53986]\n",
            " [  8.1       5.       24.96674 121.54067]\n",
            " [  6.5       9.       24.97433 121.5431 ]]\n",
            "[ 37.9  42.2  47.3  54.8  43.1  32.1  40.3  46.7  18.8  22.1  41.4  58.1\n",
            "  39.3  23.8  34.3  50.5  70.1  37.4  42.3  47.7  29.3  51.6  24.6  47.9\n",
            "  38.8  27.   56.2  33.6  47.   57.1  22.1  25.   34.2  49.3  55.1  27.3\n",
            "  22.9  25.3  47.7  46.2  15.9  18.2  34.7  34.1  53.9  38.3  42.   61.5\n",
            "  13.4  13.2  44.2  20.7  27.   38.9  51.7  13.7  41.9  53.5  22.6  42.4\n",
            "  21.3  63.2  27.7  55.   25.3  44.3  50.7  56.8  36.2  42.   59.   40.8\n",
            "  36.3  20.   54.4  29.5  36.8  25.6  29.8  26.5  40.3  36.8  48.1  17.7\n",
            "  43.7  50.8  27.   18.3  48.   25.3  45.4  43.2  21.8  16.1  41.   51.8\n",
            "  59.5  34.6  51.   62.2  38.2  32.9  54.4  45.7  30.5  71.   47.1  26.6\n",
            "  34.1  28.4  51.6  39.4  23.1   7.6  53.3  46.4  12.2  13.   30.6  59.6\n",
            "  31.3  48.   32.5  45.5  57.4  48.6  62.9  55.   60.7  41.   37.5  30.7\n",
            "  37.5  39.5  42.2  20.8  46.8  47.4  43.5  42.5  51.4  28.9  37.5  40.1\n",
            "  28.4  45.5  52.2  43.2  45.1  39.7  48.5  44.7  28.9  40.9  20.7  15.6\n",
            "  18.3  35.6  39.4  37.4  57.8  39.6  11.6  55.5  55.2  30.6  73.6  43.4\n",
            "  37.4  23.5  14.4  58.8  58.1  35.1  45.2  36.5  19.2  42.   36.7  42.6\n",
            "  15.5  55.9  23.6  18.8  21.8  21.5  25.7  22.   44.3  20.5  42.3  37.8\n",
            "  42.7  49.3  29.3  34.6  36.6  48.2  39.1  31.6  25.5  45.9  31.5  46.1\n",
            "  26.6  21.4  44.   34.2  26.2  40.9  52.2  43.5  31.1  58.   20.9  48.1\n",
            "  39.7  40.8  43.8  40.2  78.3  38.5  48.5  42.3  46.   49.   12.8  40.2\n",
            "  46.6  19.   33.4  14.7  17.4  32.4  23.9  39.3  61.9  39.   40.6  29.7\n",
            "  28.8  41.4  33.4  48.2  21.7  40.8  40.6  23.1  22.3  15.   30.   13.8\n",
            "  52.7  25.9  51.8  17.4  26.5  43.9  63.3  28.8  30.7  24.4  53.   31.7\n",
            "  40.6  38.1  23.7  41.1  40.1  23.  117.5  26.5  40.5  29.3  41.   49.7\n",
            "  34.   27.7  44.   31.1  45.4  44.8  25.6  23.5  34.4  55.3  56.3  32.9\n",
            "  51.   44.5  37.   54.4  24.5  42.5  38.1  21.8  34.1  28.5  16.7  46.1\n",
            "  36.9  35.7  23.2  38.4  29.4  55.   50.2  24.7  53.   19.1  24.7  42.2\n",
            "  78.   42.8  41.6  27.3  42.   37.5  49.8  26.9  18.6  37.7  33.1  42.5\n",
            "  31.3  38.1  62.1  36.7  23.6  19.2  12.8  15.6  39.6  38.4  22.8  36.5\n",
            "  35.6  30.9  36.3  50.4  42.9  37.   53.5  46.6  41.2  37.9  30.8  11.2\n",
            "  53.7  47.   42.3  28.6  25.7  31.3  30.1  60.7  45.3  44.9  45.1  24.7\n",
            "  47.1  63.3  40.   48.   33.1  29.5  24.8  20.9  43.1  22.8  42.1  51.7\n",
            "  41.5  52.2  49.5  23.8  30.5  56.8  37.4  69.7  53.3  47.3  29.3  40.3\n",
            "  12.9  46.6  55.3  25.6  27.3  67.7  38.6  31.3  35.3  40.3  24.7  42.5\n",
            "  31.9  32.2  23.   37.3  35.5  27.7  28.5  39.7  41.2  37.2  40.5  22.3\n",
            "  28.1  15.4  50.   40.6  52.5  63.9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.reshape((414,1))\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDOSNjEp1b4X",
        "outputId": "8b876b7b-6e1e-4a4b-8569-d85ec8f79e2b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(414, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linearmodel = LinearRegression()"
      ],
      "metadata": {
        "id": "fRrCX5oAynf6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta, costs = linearmodel.fit(X, y)"
      ],
      "metadata": {
        "id": "7UHjQ9o8zy8G"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GsUKlQ811g_",
        "outputId": "df33fda3-fedb-46f1-f0a4-aa3b8b1ff914"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.95430851e+30],\n",
              "       [3.49038840e+31],\n",
              "       [8.00978389e+30],\n",
              "       [4.87972149e+31],\n",
              "       [2.37513677e+32]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "costs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFhnYVed13G6",
        "outputId": "1dc7bc5f-47fd-4f88-f03a-4813a49554de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[17584469.24866178,\n",
              " 429467665847.9636,\n",
              " 1.0488991573249486e+16,\n",
              " 2.561751512226611e+20,\n",
              " 6.25662702135463e+24,\n",
              " 1.5280709896144735e+29,\n",
              " 3.7320443448709856e+33,\n",
              " 9.114861211780159e+37,\n",
              " 2.226144365733322e+42,\n",
              " 5.436965656351846e+46,\n",
              " 1.3278831329796415e+51,\n",
              " 3.2431207520905476e+55,\n",
              " 7.9207514211279625e+59,\n",
              " 1.934504074042235e+64,\n",
              " 4.72468559296495e+68]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linearmodel.predict(X)"
      ],
      "metadata": {
        "id": "F8fml04q17OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Logistic Regression**"
      ],
      "metadata": {
        "id": "BocLMYRzyyUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "993pV74Sy1eZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_iris(return_X_y=True)"
      ],
      "metadata": {
        "id": "WRU03w3z3zDw"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kYE3xu-31aG",
        "outputId": "e834fd73-276b-4f9f-e596-5e01cd100609"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.reshape((len(y),1))\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R9k6elF32pO",
        "outputId": "bbd6f9eb-ca01-4dfd-a244-9b86cc3928de"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.where(y==1, 0, 1)"
      ],
      "metadata": {
        "id": "UVwOxg7j8eZP"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZqtKP0588ed",
        "outputId": "d4d7beff-eaea-4277-c0c7-610968a83610"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logisticmodel = LogisticRegression()"
      ],
      "metadata": {
        "id": "jOG80UbZ33mf"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta1, costs1 = logisticmodel.fit(X, y, iters=20, learning_rate=0.1, loss='crossentropy')"
      ],
      "metadata": {
        "id": "KFExsMZm4KKo"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhHzmM-V4VqW",
        "outputId": "df59b453-2863-400b-b006-d6f9d6db45d3"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02402407],\n",
              "       [ 0.09978285],\n",
              "       [ 0.24385102],\n",
              "       [-0.16425354],\n",
              "       [-0.02256805]])"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "costs1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BV-T_6L49Td",
        "outputId": "82c41ab2-702f-44c7-eeb1-6a4705888688"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6513035021480682,\n",
              " 0.637076241590133,\n",
              " 0.6321563490621346,\n",
              " 0.6283492430805254,\n",
              " 0.6250014727726031,\n",
              " 0.6219618853913907,\n",
              " 0.619184044094222,\n",
              " 0.616639294880123,\n",
              " 0.6143041108143823,\n",
              " 0.6121578240190163,\n",
              " 0.6101819988458836,\n",
              " 0.608360152170229,\n",
              " 0.6066775271197683,\n",
              " 0.6051209036987233,\n",
              " 0.6036784290689496,\n",
              " 0.6023394677125302,\n",
              " 0.6010944681216385,\n",
              " 0.5999348446500585,\n",
              " 0.5988528727000604,\n",
              " 0.5978415958111765]"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logisticmodel.predict(X) #Vì data ít nên kết quả chưa tốt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3sYwZP5ATu",
        "outputId": "ae2e3b9f-fc50-482b-efe0-de50efa30fff"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logisticmodel = LogisticRegression()"
      ],
      "metadata": {
        "id": "fTdkTIFc7dEH"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta2, costs2 = logisticmodel.fit(X, y, iters=15, loss='mse') #Sử dụng mean squared error cho logistic regression"
      ],
      "metadata": {
        "id": "9I-_DxzJ660b"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1d_jNNL7M21",
        "outputId": "40e23c3e-ddbb-460a-b642-efdffb0598da"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0113224 ],\n",
              "       [0.05995518],\n",
              "       [0.0490309 ],\n",
              "       [0.01435911],\n",
              "       [0.00595626]])"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "costs2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqr8PgOS7kEk",
        "outputId": "c9d2f219-b278-4727-9454-1b69b300a250"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12149171918419262,\n",
              " 0.11896663508204341,\n",
              " 0.11714160476380528,\n",
              " 0.11581203805309297,\n",
              " 0.11483269133525843,\n",
              " 0.11410129993055691,\n",
              " 0.11354604413266882,\n",
              " 0.11311644339551992,\n",
              " 0.11277691729897525,\n",
              " 0.11250229186633977,\n",
              " 0.11227467983242104,\n",
              " 0.11208131591011916,\n",
              " 0.11191305134245298,\n",
              " 0.1117633029409121,\n",
              " 0.11162731598477872]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logisticmodel.predict(X)"
      ],
      "metadata": {
        "id": "fyYVxh_o7lJD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}